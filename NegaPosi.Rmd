---
title: "Tweetsの時系列分析・他"
author: "石田基広"
date: "2021/12/13"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=FALSE, cache = TRUE)
library(tidyverse)
```


# Tweetsデータ取得の準備


```{r}
library(tidyverse)
library(rtweet)
x <- search_tweets("自民党", n = 1)
x$text
```

## 言語指定でツィートを取得する方法


```{r}
tweets <- search_tweets("lang:jp", n = 1000, include_rts = FALSE)
```

```{r}
tweets %>% select(text)
```


```{r}
View(tweets)
```


## 画像を取り出す


```{r}
with_pictures <- search_tweets("#日本の絶景", n = 10,  include_rts = FALSE)
```

データのどこに画像情報があるのか？

```{r}
with_pictures %>% select(ext_media_url)  %>% unnest(cols = c(ext_media_url)) 
```


```{r}
pic_url <- with_pictures %>% select(ext_media_url)  %>% unnest(cols = c(ext_media_url)) 
```


```{r}
## 画像のurl ext_media_url を抽出
pic_url <- with_pictures %>% 
  ## あるツィートに画像のurlが複数ある場合がある
  unnest(cols = ext_media_url) %>% 
  ## \画像がないツィートもあるので削除
  filter(!is.na(ext_media_url)) %>%  #
  # 投稿日時と Tweets、投稿者、そして URLのみを抽出
  select(created_at, screen_name, text, ext_media_url)
```


```{r}
pic_url
```


画像を一気に保存するため、画像のURLを取り出す

```{r}
urls <- pic_url %>% select(ext_media_url) %>% pull()
```

```{r}
# 保存場所を指定
setwd("/home/ishida/tmp")
# setwd("C:/Users/Ishida/Downloads")
```

```{r}
# 保存するための関数
get_pictures <- function(url){
  id <- str_remove(url, "http://pbs.twimg.com/media/")
  download.file(url = url, destfile = id)
  ## サーバに対する礼儀
  Sys.sleep(1)
}
```

## Web Scraping

実行する

```{r}
urls %>% map(~ get_pictures(.x))
```


## ツィートからヒートマップ

毎日のツィート数を可視化

```{r}
## アカウント指定でツイートを収集
tw_data <- get_timeline("hirox246", n = 3200, include_rts = FALSE)
```
```{r}
dim(tw_data)
```


日付で投稿数を確認するのを目的とする。テキストそのものは使わない。日付列だけを残す。ただし、デフォルトだと世界標準時間(UTC)なので、日本標準時間(JST) に変換する。

```{r}
as.Date(as.POSIXct("2020-05-01 8:00:00")) # 2020-04-30 23:00 へ変換してから時間情報を削除
as.Date(as.POSIXct("2020-05-01 9:00:00")) # 2020-05-01 00:00 へ変換してから時間情報を削除されている

# UTC に統一して変換
td <- as.POSIXct("2020-05-01 8:00:00", tz = "UTC")
as.Date(td)
```

１行目のデータのタイムゾーンをJSTで表示
```{r}
tw_data %>% slice(1) %>% select (created_at) %>%
  # Twitter データのデフォルトはUTC
    mutate(created_at = as.POSIXct(x = created_at, tz="UTC")) %>%pull() %>% as.Date() 

```



すべての日付を変更し、別名で保存

```{r}
dates_tw <- tw_data %>% select (created_at) %>% mutate(created_at = as.POSIXct(x = created_at, tz="UTC")) %>% pull() %>% as.Date() 
```


```{r}
dates_tw %>% tail()
```

時間の設定


```{r}
# 日付時間を扱うパッケージ
library(lubridate)
tw_count <- dates_tw %>% 
  # 指定した時間単位で区切る
  floor_date(unit = "day") %>% 
  # Date型に変換
  as_date() %>% 
  # データフレームに変換
  tibble(terms = .) %>%
  # ツイート数をカウント
  count(terms) 

```

```{r}
tw_count %>% tail()
```

```{r}
NROW(tw_count)
```

毎日どれくらいつぶやいているかを確認するグラフを作成しますが、あるいは０回という日があるかもしれませんが、そういう日付は落ちています。例えば９月２４日にツィートが７個あり、９月２５日は０，そして９月２６日１１個という場合、データには４月２日を表す行がありません。

1 2020-09-24     7
2 2020-09-26    11
3 2020-09-27     2


そこで、いったん、取得したツィートの期間すべてを表す表を作成し、その表にツィート数を埋め込んでいくという処理を行います。
もしも、該当する日付がない場合は、０を埋め込みます。


```{r}
# ツイート期間を表すデータフレームを作成
term_df <- seq(
  # 一番古い日時
  floor_date(tail(dates_tw, 1), "day"),
  # 現在日時
  floor_date(now(), "day"), 
  by = "day"
) %>% 
  # 指定した期間のベクトルを作成
  as_date() %>% 
  tibble(terms = .)

# 作成した表と集計結果を結合
tw_count2 <- left_join(term_df, tw_count, by = "terms") %>% 
  mutate(n = replace_na(n, 0)) # NAを0に置換

```

```{r}
# グラフのラベル用にデータフレームを整形
  tw_count2 <- tw_count2 %>% 
  # 年月を抽出
    mutate(year_mon = format(terms, "%Y-%m")) %>% 
  # 日を抽出
    mutate(day = format(terms, "%d")) 
```


```{r}
tw_count2 %>% ggplot(aes(x = year_mon, y = day, fill = n)) + 
    geom_tile() + 
  # ヒートマップ
    scale_fill_gradient(low = "white" , high = "#00A968") + 
  # 凡例の濃淡
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) + # 軸目盛の傾き
    labs(title = paste0("@hirox246のツイート数"), 
         x = "year-mon", y = "day") 
```



## ネガポジ分析

ネガポジ判定に有効でない語や文字を省く

```{r}
# テキストの抽出と文字列処理
tw_text <- tw_data  %>% select(text) %>% pull() %>%  
  # リプライの除去
  str_remove_all("^@.*?\\s") %>% 
  # urlの除去
  str_remove_all(("https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+")) %>% 
  # # 絵文字の除去（
  str_remove_all("[\U0001F004-\U000207BF]") 
```


```{r}
# 期間ごとにまとめる
text_df <- data.frame(
  # 日付で区切る
  terms = as.Date(floor_date(dates_tw, "day")), 
  texts = tw_text
) %>% 
  group_by(terms) %>% 
  # 同じ日付のツィートを1つにまとめる
  summarise(texts = paste(texts, collapse = "\n")) 
```

```{r}
text_df %>% slice(1) %>% select(texts) %>% pull()
```

```{r}
text_df %>% colnames()
```

日付ごとに形態素解析にかける
```{r}
library(RMeCab)
rmecabrc <- function(term, text){
  x <- unlist(RMeCabC(text, 1))
  tibble(Day = term, TERM= x)
}
```

```{r}
day_df <- map2_dfr(text_df$terms, text_df$texts,
                   ~rmecabrc(..1, ..2))
```


```{r}
day_df %>% head()
```

```{r}
# 単語感情極性対応表の取得
dic <- read.table(
  "http://www.lr.pi.titech.ac.jp/~takamura/pubs/pn_ja.dic", 
  sep = ":", stringsAsFactors = FALSE,fileEncoding = "CP932"
)

```

```{r}
dic %>% NROW()
```


```{r}
dic %>% filter(V1 == "大人")
```


## 辞書の列名を変更

```{r}
dic <- dic %>% rename(TERM = V1, POS1 = V3)
```

## ツィート形態素解析結果と辞書を結合
```{r}
# day_df <- day_df %>% left_join(dic)
day_df <- day_df %>% left_join(dic, by = c("TERM", "POS1"))
```

```{r}
day_df %>% head()
```

## 単語の各スコアごとにカテゴリを設定（ポジティブ、ネガティブ、ニュートラルと分類）
```{r}
day_df2 <- day_df %>% mutate(FLAG_SCORE = case_when(
  is.na(V4) ~ "neutral",
  V4 < 0 ~ "negative",
  V4 > 0 ~ "positive",
  V4 == 0 ~ "neutral"))

```

```{r}
day_df2 %>% head()
```

## 日付と、カテゴリごとに合算値を得る

```{r}
day_df3 <- day_df2 %>% group_by(Day, FLAG_SCORE) %>% summarise(NP = sum(V4, na.rm = TRUE))
```


```{r}
day_df3 %>% head()
```


## 可視化

```{r}
# ネガポジ推移
day_df3 %>% ggplot(aes(x = Day, y = NP)) + 
  geom_bar(mapping = aes(fill = FLAG_SCORE, color = FLAG_SCORE), stat = "identity") + # 棒グラフ
  scale_fill_manual(values = c("#00A968", "yellow", "orange")) + # 塗りつぶしの色
scale_color_manual(values = c("#00A968", "yellow", "orange")) + # 枠の色
  geom_line(stat = "summary", fun = "sum", color = "blue", alpha=0.5) + # 折れ線グラフ
  scale_x_date(date_breaks = "1 week") + # x軸目盛(day)
  #scale_x_date(date_breaks = "1 month", date_labels = "%Y-%m") + # x軸目盛(mon)
  theme(axis.text.x = element_text(angle = 90)) + # x軸目盛の傾き
  labs(title = paste0("@hiroxのネガポジ推移（青は合算値）")) # ラベル
```


